{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "#Se importa el archivo pickle\n",
    "with open('scrap_info_alq.pkl', 'rb') as f:\n",
    "    diccionario = pickle.load(f)\n",
    "\n",
    "\n",
    "with open('scrap_info.pkl', 'rb') as f:\n",
    "    diccionario2 = pickle.load(f)\n",
    "#Se transforma el diccionario en un dataframe\n",
    "df = pd.DataFrame(diccionario)\n",
    "df2 = pd.DataFrame(diccionario2)\n",
    "#Ahora se cambia las filas por las columnas\n",
    "df = df.T\n",
    "df2 = df2.T\n",
    "df.head()\n",
    "df2.head()\n",
    "\n",
    "#Ahora unimos los dos dataframes\n",
    "df_def = pd.concat([df,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pjcan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pjcan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pjcan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indomio.es/anuncios/95227781/    alquila piso amueblado habitaciones carrer del...\n",
      "https://www.indomio.es/anuncios/95146207/    piso estudiantes entrar partir ro febrero juni...\n",
      "https://www.indomio.es/anuncios/94613177/    disponible alquiler mensual anual bajo dormito...\n",
      "https://www.indomio.es/anuncios/94500757/    disponible alquiler mensual anual bajo dormito...\n",
      "https://www.indomio.es/anuncios/95223135/    rincón acogedor necesito espacio gustará aquí ...\n",
      "                                                                   ...                        \n",
      "https://www.indomio.es/anuncios/95007509/    atico m valencia valencia solidinmuebles vende...\n",
      "https://www.indomio.es/anuncios/94958481/    venden pisos obra nueva camino moncada trata r...\n",
      "https://www.indomio.es/anuncios/95006805/    vende exclusiva viviendas obra nueva calle arq...\n",
      "https://www.indomio.es/anuncios/95313313/    vende piso barrio tormoseste luminoso apartame...\n",
      "https://www.indomio.es/anuncios/95319871/    piso ideal inversionistas gran oportunidad adq...\n",
      "Name: Descripcion, Length: 1559, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Descargar los recursos necesarios para NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if text is None:\n",
    "        return ''\n",
    "    # Convertir texto a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar caracteres especiales y números\n",
    "    text = re.sub(r'[^a-záéíóúüñ\\s]', '', text)\n",
    "    # Tokenización\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Eliminar stopwords\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lematización\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "descripcion_filtrada = df_def['Descripcion'].apply(preprocess_text)\n",
    "\n",
    "print(descripcion_filtrada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14497312, -0.26972876,  0.78737534, ...,  0.02087234,\n",
       "        -0.10260844,  0.06362454],\n",
       "       [ 0.18997783, -0.19594662,  0.03322387, ...,  0.05826937,\n",
       "        -0.0366585 ,  0.09769377],\n",
       "       [ 0.28900457, -0.31092992, -0.08249069, ...,  0.04435693,\n",
       "         0.11768029,  0.0356905 ],\n",
       "       ...,\n",
       "       [ 0.25781214, -0.23456174, -0.06241935, ..., -0.0810347 ,\n",
       "         0.02747867, -0.05118084],\n",
       "       [ 0.39467638, -0.38163988,  0.00312988, ...,  0.06312087,\n",
       "        -0.18018953,  0.16932089],\n",
       "       [ 0.31317552, -0.33143523,  0.01432733, ..., -0.00864162,\n",
       "         0.03434649, -0.03294247]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "tv = TfidfVectorizer()\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "lsa = make_pipeline(tv, svd, Normalizer(copy=False))\n",
    "lsa_topic_vectors = lsa.fit_transform(descripcion_filtrada)\n",
    "\n",
    "lsa_topic_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descripción: DISPONIBLE A PARTIR DE JULIO 2024. ALQUILER PARA ESTUDIANTES UNIVERSITARIOS (CONTRATO DE TEMPORADA). Se alquila este precioso apartamento , semireformado, en un edificio tranquilo y en una zona ideal si te gusta tener todo a un paso. Se trata de una vivienda con un total de 4 habitaciones y dos cuartos de baños completos. el apartamento se distribuye en zona de salón comedor con acceso a balcón y aire acondicionado (frío /calor), 4 habitaciones con camas de 1,35, totalmente equipadas y dos cuartos de baños completos. Cocina independiente, con todo lo que puedas necesitar en tu día a día y con acceso directo a terraza en zona común, pero de uso privativo. Como ves el piso lo tiene todo, es bonito, esta cerca de transporte público, tanto metro como autobús en menos de 9 minutos a pie, 5 minutos andando de supermercado y el mercado municipal del Cabañal a 7 minutos y lo mejor de todo, a tan solo 16 minutos a pie de la playa. No se puede pedir más. Si estás buscando una vivienda en condiciones, que además te ofrezca comodidad y tranquilidad, no lo dudes, esta es la tuya, así que llámanos y estaremos encantados de poder ayudarte. INCLUYE LIMPIEZA MENSUAL DE ZONAS COMUNES. El precio del alquiler a partir del mes de Julio es 1.300 €./mes.\n",
      "Similitud: 0.5640341673046437\n",
      "\n",
      "Descripción: ALQUILER PARA ESTUDIANTES UNIVERSITARIOS (CONTRATO DE TEMPORADA). Se alquila este precioso apartamento , semireformado, en un edificio tranquilo y en una zona ideal si te gusta tener todo a un paso. Se trata de una vivienda con un total de 4 habitaciones y dos cuartos de baños completos. el apartamento se distribuye en zona de salón comedor con acceso a balcón y aire acondicionado (frío /calor), 4 habitaciones con camas de 1,35, totalmente equipadas y dos cuartos de baños completos. Cocina independiente, con todo lo que puedas necesitar en tu día a día y con acceso directo a terraza en zona común, pero de uso privativo. Como ves el piso lo tiene todo, es bonito, esta cerca de transporte público, tanto metro como autobús en menos de 9 minutos a pie, 5 minutos andando de supermercado y el mercado municipal del Cabañal a 7 minutos y lo mejor de todo, a tan solo 16 minutos a pie de la playa. No se puede pedir más. Si estás buscando una vivienda en condiciones, que además te ofrezca comodidad y tranquilidad, no lo dudes, esta es la tuya, así que llámanos y estaremos encantados de poder ayudarte. INCLUYE LIMPIEZA MENSUAL DE ZONAS COMUNES. El precio del alquiler a partir del mes de Julio es 1.300 €./mes.\n",
      "Similitud: 0.5614015861018384\n",
      "\n",
      "Descripción: GRAN OPORTUNIDAD DE INVERSIÓN EN PISO DE ESTUDIANTES La vivienda está recién reformada, ubicada a menos de 500m de una de las mejores playas de Valencia, así como a 700m de la Universidad Politécnica de Valencia. Cuenta con la parada de tranvía justo en frente, así como supermercados, bancos, restaurantes y Universidades. El barrio del Cabanyal en Poblats Maritims, es perfecto para invertir, ya que se trata de un punto intermedio entre la zona universitaria y la zona turística; pudiendo de esta forma lograr un alquiler durante el período del curso escolar, y turístico en los meses de verano. La vivienda cuenta con 76m2, reforma intregral y equipamiento en cada uno de los espacios. Las 4 habitaciones están amuebladas (2 de ellas exteriores); 2 baños completos con plato de ducha e hidromasaje. Cocina equipada con todos los electrodomésticos básicos, además de lavavajillas y Ósmosis (purificador de agua). Se trata de una segunda planta sin ascensor\n",
      "Similitud: 0.492182548595566\n",
      "\n",
      "Descripción: Se venden pisos de obra nueva en el camino de Moncada. Se trata de un residencial de 14 apartamentos de 2 o 3 habitaciones y 2 baños, y dos áticos. Zonas comunes ajardinadas y con piscina. Entrega prevista primavera 2026. Facilidades de pago. Precio a partir de 230.000€. Plaza de garaje y trastero opcional\n",
      "Similitud: 0.48999504892304063\n",
      "\n",
      "Descripción: SE VENDE EXCLUSIVO PISO . SEMI NUEVO En la zona nueva de Nazaret junto a las torres y aun paso de la playa. Piso De altas calidades en RESIDENCIAL con zonas comunes Piscina pádel zona para niños. El piso se distribuye en 84M2 y 100M2 construidos . Fantástico comedor con salida a la terraza con cerramiento de cristales en forma de laminas y correderos . cocina independiente 3 habitaciones dobles 2 baños completos una amplia plaza de garaje incluida en el precio.. MAS INFORMACION O HACER UNA VISITA TONTACTANOS !!!\n",
      "Similitud: 0.48906129408298665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Nueva descripción\n",
    "descripcion = \"Quiero un piso de unos 100 m2 que este bien iluminado, cueste menos de 700 euros al mes, este en la zona de campanar y tenga por lo menos 3 habitaciones y 2 baños\"\n",
    "\n",
    "# Transformar la nueva descripción usando la misma pipeline LSA\n",
    "vector_descripcion = lsa.transform([descripcion])\n",
    "\n",
    "# Calcular la similitud coseno entre la nueva descripción y todas las descripciones existentes\n",
    "similarities = cosine_similarity(vector_descripcion, lsa_topic_vectors)\n",
    "\n",
    "# Obtener los índices de las descripciones más similares en orden descendente\n",
    "most_similar_indices = similarities.argsort()[0][::-1]\n",
    "\n",
    "# Opcionalmente, puedes mostrar las descripciones más similares y sus similitudes\n",
    "for index in most_similar_indices[:5]:  # muestra las 5 descripciones más similares\n",
    "    print(f\"Descripción: {df_def['Descripcion'].iloc[index]}\")\n",
    "    print(f\"Similitud: {similarities[0][index]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2)\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(descripcion_filtrada)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=10, max_iter=5,\n",
    "learning_method='online',\n",
    "learning_offset=50.,\n",
    "random_state=0)\n",
    "\n",
    "lda_topic_matrix = lda.fit_transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descripción: Bonito piso recién reformado. Está todo a estrenar! A tan solo unos minutos de la plaza del Ayuntamienti y del Mercado Central. \n",
      "Similitud: 0.9999964260327222\n",
      "\n",
      "Descripción: Piso en pleno centro de Valencia de 545 m2 con terrazas muy grandes. Dispone de un apartamento añadido para los invitados.el piso es de estilo señorial con acabados de primera calidad reformado y a estrenar.\n",
      "Similitud: 0.9999261534660971\n",
      "\n",
      "Descripción: Apartamento de 3 dormitorios en una excelente ubicación, Restaurantes, supermercados cercas.El dormitorio principal tiene un vestidor y un baño en suite. La cocina está amueblada con área de lavandería separada. Aire acondicionado\n",
      "Similitud: 0.9999139048645553\n",
      "\n",
      "Descripción: Un encantador apartamento con lindas paredes azules en la sala de estar, una espaciosa cocina y una gran terraza en un vecindario tranquilo y residencial. El apartamento está a solo 10 minutos a pie del puerto de Valencia, y cerca encontrará algunas tiendas, una piscina municipal y una estación de servicio.\n",
      "Similitud: 0.9998425794909527\n",
      "\n",
      "Descripción: Un amplio apartamento en una zona costera de la ciudad y a 7 minutos de la Universitat de València desde la parada de tranvía más cercana. Cuenta con 2 balcones y una cocina totalmente equipada. Solo tiene que caminar durante 7 minutos para encontrarse en las arenas doradas de Playa de la Malva-Rosa, una playa relajada popular entre los lugareños.\n",
      "Similitud: 0.9998343436181891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Nueva descripción\n",
    "descripcion = \"Quiero un piso de unos 100 m2 que este bien iluminado, cueste menos de 700 euros al mes, este en la zona de campanar y tenga por lo menos 3 habitaciones y 2 baños\"\n",
    "\n",
    "# Transformar la nueva descripción\n",
    "vector_descripcion = tf_vectorizer.transform([descripcion])\n",
    "vector_descripcion_lda = lda.transform(vector_descripcion)\n",
    "\n",
    "# Calcular la similitud coseno entre la nueva descripción y las descripciones existentes\n",
    "similarities = cosine_similarity(vector_descripcion_lda, lda_topic_matrix)\n",
    "\n",
    "# Obtener los índices de las descripciones más similares en orden descendente\n",
    "most_similar_indices = similarities.argsort()[0][::-1]\n",
    "\n",
    "# Mostrar las descripciones más similares y sus similitudes\n",
    "for index in most_similar_indices[:5]:  # muestra las 5 descripciones más similares\n",
    "    print(f\"Descripción: {df_def['Descripcion'].iloc[index]}\")\n",
    "    print(f\"Similitud: {similarities[0][index]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobar la coherencia de los topics LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'triu' from 'scipy.linalg' (c:\\Users\\pjcan\\anaconda3\\envs\\prueba\\lib\\site-packages\\scipy\\linalg\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcoherencemodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CoherenceModel\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpora\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdictionary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dictionary\n",
      "File \u001b[1;32mc:\\Users\\pjcan\\anaconda3\\envs\\prueba\\lib\\site-packages\\gensim\\__init__.py:11\u001b[0m\n\u001b[0;32m      7\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.3.2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mhandlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pjcan\\anaconda3\\envs\\prueba\\lib\\site-packages\\gensim\\corpora\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexedcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmmcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleicorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pjcan\\anaconda3\\envs\\prueba\\lib\\site-packages\\gensim\\corpora\\indexedcorpus.py:14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[0;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIndexedCorpus\u001b[39;00m(interfaces\u001b[38;5;241m.\u001b[39mCorpusABC):\n",
      "File \u001b[1;32mc:\\Users\\pjcan\\anaconda3\\envs\\prueba\\lib\\site-packages\\gensim\\interfaces.py:19\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[0;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCorpusABC\u001b[39;00m(utils\u001b[38;5;241m.\u001b[39mSaveLoad):\n",
      "File \u001b[1;32mc:\\Users\\pjcan\\anaconda3\\envs\\prueba\\lib\\site-packages\\gensim\\matutils.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m entropy\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_blas_funcs, triu\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlapack\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_lapack_funcs\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m psi  \u001b[38;5;66;03m# gamma function utils\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'triu' from 'scipy.linalg' (c:\\Users\\pjcan\\anaconda3\\envs\\prueba\\lib\\site-packages\\scipy\\linalg\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Paso 1: Preparar datos para gensim\n",
    "# Convertir el texto tokenizado (asumiendo que tienes 'descripcion_filtrada' como una lista de listas de palabras)\n",
    "texts = [doc.split() for doc in descripcion_filtrada]\n",
    "\n",
    "# Crear un diccionario de Gensim a partir de los textos\n",
    "dictionary = Dictionary(texts)\n",
    "\n",
    "# Crear un corpus de Gensim utilizando el diccionario\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Paso 2: Extraer los tópicos del modelo LDA de scikit-learn\n",
    "topics = []\n",
    "feature_names = tf_vectorizer.get_feature_names_out()\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    topics.append([feature_names[i] for i in topic.argsort()[:-10 - 1:-1]])\n",
    "\n",
    "# Paso 3: Calcular la coherencia del modelo\n",
    "cm = CoherenceModel(model=None, topics=topics, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence = cm.get_coherence()\n",
    "print(\"Coherencia del modelo LDA:\", coherence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'prueba' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n prueba ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Inicialización de CountVectorizer\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2)\n",
    "tf = tf_vectorizer.fit_transform(descripcion_filtrada)\n",
    "\n",
    "# Uso de NMF\n",
    "nmf = NMF(n_components=10, random_state=0, max_iter=300)\n",
    "\n",
    "# Transformar los datos con NMF\n",
    "nmf_topic_matrix = nmf.fit_transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'prueba' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n prueba ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Nueva descripción a comparar\n",
    "descripcion = \"Quiero un piso de unos 100 m2 que este bien iluminado, cueste menos de 700 euros al mes, este en la zona de campanar y tenga por lo menos 3 habitaciones y 2 baños\"\n",
    "\n",
    "# Transformar la nueva descripción usando el mismo vectorizador\n",
    "vector_descripcion = tf_vectorizer.transform([descripcion])\n",
    "vector_descripcion_nmf = nmf.transform(vector_descripcion)\n",
    "\n",
    "# Calcular la similitud coseno entre la nueva descripción y las descripciones existentes transformadas\n",
    "similarities = cosine_similarity(vector_descripcion_nmf, nmf_topic_matrix)\n",
    "\n",
    "# Obtener los índices de las descripciones más similares en orden descendente\n",
    "most_similar_indices = similarities.argsort()[0][::-1]\n",
    "\n",
    "# Mostrar las descripciones más similares y sus similitudes\n",
    "for index in most_similar_indices[:5]:  # muestra las 5 descripciones más similares\n",
    "    print(f\"Descripción: {df_def['Descripcion'].iloc[index]}\")\n",
    "    print(f\"Similitud: {similarities[0][index]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobar la coherencia de los topics NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'prueba' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n prueba ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Paso 1: Preparar datos para gensim\n",
    "texts = [doc.split() for doc in descripcion_filtrada]\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Paso 2: Extraer los tópicos del modelo NMF\n",
    "topics = []\n",
    "feature_names = tf_vectorizer.get_feature_names_out()\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    top_features_ind = topic.argsort()[:-10 - 1:-1]  # obtener los índices de las palabras más importantes\n",
    "    topic_words = [feature_names[i] for i in top_features_ind]\n",
    "    topics.append(topic_words)\n",
    "\n",
    "# Paso 3: Calcular la coherencia del modelo\n",
    "cm = CoherenceModel(topics=topics, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence = cm.get_coherence()\n",
    "print(\"Coherencia del modelo NMF:\", coherence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrar palabras clave de cada tema en NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'prueba' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n prueba ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Obtener las palabras del vocabulario\n",
    "feature_names = tf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Función para mostrar las palabras clave por tema\n",
    "def show_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic #{topic_idx + 1}:\")\n",
    "        # Muestra las n_top_words palabras más importantes por tema\n",
    "        top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_features = [feature_names[i] for i in top_features_ind]\n",
    "        top_features_str = \", \".join(top_features)\n",
    "        print(f\"Palabras clave: {top_features_str}\\n\")\n",
    "\n",
    "# Mostrar las palabras clave de cada tema\n",
    "n_top_words = 10\n",
    "show_top_words(nmf, feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'prueba' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n prueba ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim import similarities\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import HdpModel\n",
    "from gensim.matutils import sparse2full\n",
    "\n",
    "# Crear un diccionario de características y filtrar palabras extremadamente frecuentes o infrecuentes\n",
    "texts = [doc.split() for doc in descripcion_filtrada]\n",
    "dictionary = Dictionary(texts)\n",
    "dictionary.filter_extremes(no_below=1, no_above=0.95)\n",
    "\n",
    "# Crear el corpus BOW\n",
    "corpus = [dictionary.doc2bow(text) for text in descripcion_filtrada]\n",
    "\n",
    "# Entrenar el modelo HDI\n",
    "hdi = HdpModel(corpus, id2word=dictionary)\n",
    "\n",
    "# Función para obtener la distribución de tópicos de un documento\n",
    "def get_topic_distribution(text):\n",
    "    bow = dictionary.doc2bow(text.lower().split())\n",
    "    return sparse2full(hdi[bow], len(hdi.id2word))\n",
    "\n",
    "# Convertir todos los documentos a vectores de tópicos\n",
    "topic_vectors = [get_topic_distribution(text) for text in descripcion_filtrada]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'prueba' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n prueba ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Nueva descripción\n",
    "descripcion = \"Quiero un piso de unos 100 m2 que este bien iluminado, cueste menos de 700 euros al mes, este en la zona de campanar y tenga por lo menos 3 habitaciones y 2 baños\"\n",
    "descripcion_vec = get_topic_distribution(descripcion)\n",
    "\n",
    "# Calcular la similitud coseno entre la nueva descripción y todas las descripciones existentes\n",
    "index = similarities.MatrixSimilarity([descripcion_vec] + topic_vectors)\n",
    "sims = index[descripcion_vec]\n",
    "\n",
    "# Obtener los índices de las descripciones más similares en orden descendente\n",
    "most_similar_indices = sims.argsort()[::-1]\n",
    "\n",
    "# Opcionalmente, muestra las descripciones más similares y sus similitudes\n",
    "for index in most_similar_indices[:5]:  # muestra las 5 descripciones más similares\n",
    "    print(f\"Descripción: {df_def['Descripcion'].iloc[index]}\")\n",
    "    print(f\"Similitud: {sims[index]}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
